{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PyTorch for CIFAR10\n",
    "We test ResNet classifier.\n",
    "First init some basic environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnet32 classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ResNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (1): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (2): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (3): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (4): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): _BasicBlock(\n",
      "      (down_sampler): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (1): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (2): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (3): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (4): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): _BasicBlock(\n",
      "      (down_sampler): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (1): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (2): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (3): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (4): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "CPU times: user 388 ms, sys: 46.4 ms, total: 435 ms\n",
      "Wall time: 567 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from cifar10.tnt_solver import *\n",
    "from cifar10.classifiers.resnet import resnet32\n",
    "\n",
    "model = resnet32()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train reset32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 1/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:20<00:00, 30.27it/s, loss:1.7759, acc:32.8200%]\n",
      "Val loss: 2.1949, accuracy: 33.75%\n",
      "Epoch: 2/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:20<00:00, 30.90it/s, loss:1.3168, acc:52.2000%]\n",
      "Val loss: 1.1978, accuracy: 56.22%\n",
      "Epoch: 3/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:20<00:00, 31.02it/s, loss:1.0446, acc:62.7400%]\n",
      "Val loss: 1.0213, accuracy: 65.09%\n",
      "Epoch: 4/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:20<00:00, 30.70it/s, loss:0.8971, acc:68.3400%]\n",
      "Val loss: 1.2004, accuracy: 62.96%\n",
      "Epoch: 5/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:21<00:00, 29.05it/s, loss:0.7760, acc:72.7775%]\n",
      "Val loss: 0.9074, accuracy: 69.03%\n",
      "Epoch: 6/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.73it/s, loss:0.7035, acc:75.5050%]\n",
      "Val loss: 0.7342, accuracy: 74.59%\n",
      "Epoch: 7/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.89it/s, loss:0.6515, acc:77.3075%]\n",
      "Val loss: 0.6525, accuracy: 77.77%\n",
      "Epoch: 8/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.71it/s, loss:0.6080, acc:78.9575%]\n",
      "Val loss: 0.7915, accuracy: 73.77%\n",
      "Epoch: 9/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.72it/s, loss:0.5773, acc:79.9950%]\n",
      "Val loss: 0.6797, accuracy: 77.90%\n",
      "Epoch: 10/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.80it/s, loss:0.5533, acc:80.9650%]\n",
      "Val loss: 0.7918, accuracy: 74.09%\n",
      "Epoch: 11/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.65it/s, loss:0.5264, acc:81.6400%]\n",
      "Val loss: 0.6431, accuracy: 79.40%\n",
      "Epoch: 12/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.82it/s, loss:0.5071, acc:82.4950%]\n",
      "Val loss: 0.7005, accuracy: 77.52%\n",
      "Epoch: 13/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.65it/s, loss:0.4866, acc:83.2300%]\n",
      "Val loss: 0.5104, accuracy: 83.12%\n",
      "Epoch: 14/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.67it/s, loss:0.4694, acc:83.8025%]\n",
      "Val loss: 0.6762, accuracy: 77.84%\n",
      "Epoch: 15/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.62it/s, loss:0.4601, acc:84.1900%]\n",
      "Val loss: 0.5947, accuracy: 79.95%\n",
      "Epoch: 16/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.72it/s, loss:0.4468, acc:84.4325%]\n",
      "Val loss: 0.5513, accuracy: 82.28%\n",
      "Epoch: 17/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.56it/s, loss:0.4356, acc:85.0050%]\n",
      "Val loss: 0.5736, accuracy: 80.09%\n",
      "Epoch: 18/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.86it/s, loss:0.4218, acc:85.4575%]\n",
      "Val loss: 0.7570, accuracy: 75.95%\n",
      "Epoch: 19/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.36it/s, loss:0.4136, acc:85.6025%]\n",
      "Val loss: 0.6506, accuracy: 78.19%\n",
      "Epoch: 20/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.32it/s, loss:0.4058, acc:85.9625%]\n",
      "Val loss: 0.5018, accuracy: 83.08%\n",
      "Epoch: 21/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.46it/s, loss:0.3972, acc:86.3350%]\n",
      "Val loss: 0.5217, accuracy: 82.38%\n",
      "Epoch: 22/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.57it/s, loss:0.3967, acc:86.1625%]\n",
      "Val loss: 0.5562, accuracy: 82.00%\n",
      "Epoch: 23/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.56it/s, loss:0.3844, acc:86.6700%]\n",
      "Val loss: 0.5870, accuracy: 81.21%\n",
      "Epoch: 24/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.57it/s, loss:0.3753, acc:86.9750%]\n",
      "Val loss: 0.5146, accuracy: 82.53%\n",
      "Epoch: 25/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.54it/s, loss:0.3703, acc:87.1800%]\n",
      "Val loss: 0.4971, accuracy: 83.96%\n",
      "Epoch: 26/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.43it/s, loss:0.3599, acc:87.5775%]\n",
      "Val loss: 0.5219, accuracy: 83.57%\n",
      "Epoch: 27/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.17it/s, loss:0.3611, acc:87.4025%]\n",
      "Val loss: 0.5399, accuracy: 82.99%\n",
      "Epoch: 28/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.37it/s, loss:0.3547, acc:87.6425%]\n",
      "Val loss: 0.4927, accuracy: 84.45%\n",
      "Epoch: 29/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.41it/s, loss:0.3477, acc:87.9450%]\n",
      "Val loss: 0.4633, accuracy: 84.92%\n",
      "Epoch: 30/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.44it/s, loss:0.3496, acc:87.8275%]\n",
      "Val loss: 0.4232, accuracy: 85.60%\n",
      "Epoch: 31/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.48it/s, loss:0.3426, acc:88.1500%]\n",
      "Val loss: 0.4951, accuracy: 82.90%\n",
      "Epoch: 32/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.49it/s, loss:0.3363, acc:88.3625%]\n",
      "Val loss: 0.4439, accuracy: 85.65%\n",
      "Epoch: 33/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.52it/s, loss:0.3317, acc:88.5600%]\n",
      "Val loss: 0.4809, accuracy: 84.62%\n",
      "Epoch: 34/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.35it/s, loss:0.3315, acc:88.7025%]\n",
      "Val loss: 0.4343, accuracy: 85.94%\n",
      "Epoch: 35/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.30it/s, loss:0.3288, acc:88.6450%]\n",
      "Val loss: 0.5469, accuracy: 82.55%\n",
      "Epoch: 36/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.40it/s, loss:0.3188, acc:88.8625%]\n",
      "Val loss: 0.7090, accuracy: 79.33%\n",
      "Epoch: 37/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.64it/s, loss:0.3207, acc:88.9400%]\n",
      "Val loss: 0.4946, accuracy: 83.76%\n",
      "Epoch: 38/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.61it/s, loss:0.3209, acc:88.8850%]\n",
      "Val loss: 0.4656, accuracy: 84.51%\n",
      "Epoch: 39/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.52it/s, loss:0.3212, acc:88.8700%]\n",
      "Val loss: 0.4411, accuracy: 85.72%\n",
      "Epoch: 40/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.60it/s, loss:0.3107, acc:89.3025%]\n",
      "Val loss: 0.6391, accuracy: 81.23%\n",
      "Epoch: 41/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.63it/s, loss:0.3120, acc:89.1650%]\n",
      "Val loss: 0.5232, accuracy: 83.62%\n",
      "Epoch: 42/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:24<00:00, 25.29it/s, loss:0.3051, acc:89.4100%]\n",
      "Val loss: 0.4516, accuracy: 86.04%\n",
      "Epoch: 43/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.60it/s, loss:0.3037, acc:89.4875%]\n",
      "Val loss: 0.4541, accuracy: 85.63%\n",
      "Epoch: 44/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.70it/s, loss:0.3051, acc:89.3550%]\n",
      "Val loss: 0.3918, accuracy: 87.45%\n",
      "Epoch: 45/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.18it/s, loss:0.3019, acc:89.4825%]\n",
      "Val loss: 0.5020, accuracy: 84.59%\n",
      "Epoch: 46/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.29it/s, loss:0.2994, acc:89.4775%]\n",
      "Val loss: 0.4184, accuracy: 86.24%\n",
      "Epoch: 47/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.32it/s, loss:0.2999, acc:89.5975%]\n",
      "Val loss: 0.4893, accuracy: 84.37%\n",
      "Epoch: 48/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.44it/s, loss:0.2964, acc:89.6600%]\n",
      "Val loss: 0.4122, accuracy: 86.69%\n",
      "Epoch: 49/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.15it/s, loss:0.2971, acc:89.6750%]\n",
      "Val loss: 0.3851, accuracy: 87.61%\n",
      "Epoch: 50/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.18it/s, loss:0.2893, acc:89.9425%]\n",
      "Val loss: 0.4731, accuracy: 85.09%\n",
      "Epoch: 51/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.26it/s, loss:0.2939, acc:89.8125%]\n",
      "Val loss: 0.5111, accuracy: 84.41%\n",
      "Epoch: 52/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.35it/s, loss:0.2937, acc:89.8225%]\n",
      "Val loss: 0.4404, accuracy: 86.16%\n",
      "Epoch: 53/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:24<00:00, 25.05it/s, loss:0.2882, acc:89.9200%]\n",
      "Val loss: 0.4153, accuracy: 86.72%\n",
      "Epoch: 54/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.37it/s, loss:0.2908, acc:89.8850%]\n",
      "Val loss: 0.5091, accuracy: 84.29%\n",
      "Epoch: 55/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.54it/s, loss:0.2882, acc:89.9900%]\n",
      "Val loss: 0.5073, accuracy: 84.20%\n",
      "Epoch: 56/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.67it/s, loss:0.2897, acc:89.9950%]\n",
      "Val loss: 0.5295, accuracy: 83.58%\n",
      "Epoch: 57/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.56it/s, loss:0.2812, acc:90.1675%]\n",
      "Val loss: 0.4451, accuracy: 85.96%\n",
      "Epoch: 58/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.27it/s, loss:0.2861, acc:90.0600%]\n",
      "Val loss: 0.3981, accuracy: 87.01%\n",
      "Epoch: 59/180, lr:1.00e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:25<00:00, 24.87it/s, loss:0.2868, acc:90.0075%]\n",
      "Val loss: 0.4606, accuracy: 85.85%\n",
      "Epoch: 60/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.24it/s, loss:0.2854, acc:90.1325%]\n",
      "Val loss: 0.4280, accuracy: 86.23%\n",
      "Epoch: 61/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.42it/s, loss:0.2796, acc:90.3400%]\n",
      "Val loss: 0.5590, accuracy: 82.98%\n",
      "Epoch: 62/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.62it/s, loss:0.2801, acc:90.1750%]\n",
      "Val loss: 0.4821, accuracy: 84.60%\n",
      "Epoch: 63/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.66it/s, loss:0.2737, acc:90.5875%]\n",
      "Val loss: 0.4111, accuracy: 87.08%\n",
      "Epoch: 64/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.77it/s, loss:0.2752, acc:90.4275%]\n",
      "Val loss: 0.3967, accuracy: 87.42%\n",
      "Epoch: 65/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.81it/s, loss:0.2760, acc:90.5075%]\n",
      "Val loss: 0.4894, accuracy: 84.85%\n",
      "Epoch: 66/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.71it/s, loss:0.2711, acc:90.6650%]\n",
      "Val loss: 0.3958, accuracy: 87.58%\n",
      "Epoch: 67/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.83it/s, loss:0.2671, acc:90.5450%]\n",
      "Val loss: 0.4210, accuracy: 87.20%\n",
      "Epoch: 68/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.98it/s, loss:0.2702, acc:90.6925%]\n",
      "Val loss: 0.3920, accuracy: 87.81%\n",
      "Epoch: 69/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.71it/s, loss:0.2750, acc:90.4850%]\n",
      "Val loss: 0.3968, accuracy: 87.30%\n",
      "Epoch: 70/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.29it/s, loss:0.2719, acc:90.5750%]\n",
      "Val loss: 0.3791, accuracy: 87.84%\n",
      "Epoch: 71/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.19it/s, loss:0.2701, acc:90.7225%]\n",
      "Val loss: 0.3841, accuracy: 87.85%\n",
      "Epoch: 72/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.12it/s, loss:0.2692, acc:90.6775%]\n",
      "Val loss: 0.4072, accuracy: 86.79%\n",
      "Epoch: 73/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.57it/s, loss:0.2783, acc:90.2375%]\n",
      "Val loss: 0.5144, accuracy: 84.07%\n",
      "Epoch: 74/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.59it/s, loss:0.2631, acc:90.8200%]\n",
      "Val loss: 0.4133, accuracy: 87.81%\n",
      "Epoch: 75/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.20it/s, loss:0.2693, acc:90.6975%]\n",
      "Val loss: 0.4408, accuracy: 85.89%\n",
      "Epoch: 76/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.28it/s, loss:0.2626, acc:90.9950%]\n",
      "Val loss: 0.4258, accuracy: 86.66%\n",
      "Epoch: 77/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.50it/s, loss:0.2651, acc:90.7250%]\n",
      "Val loss: 0.4710, accuracy: 86.05%\n",
      "Epoch: 78/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.23it/s, loss:0.2680, acc:90.8100%]\n",
      "Val loss: 0.4992, accuracy: 84.99%\n",
      "Epoch: 79/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.15it/s, loss:0.2665, acc:90.6800%]\n",
      "Val loss: 0.4603, accuracy: 85.74%\n",
      "Epoch: 80/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.18it/s, loss:0.2625, acc:90.8375%]\n",
      "Val loss: 0.3743, accuracy: 88.11%\n",
      "Epoch: 81/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.34it/s, loss:0.2594, acc:91.0600%]\n",
      "Val loss: 0.4488, accuracy: 86.31%\n",
      "Epoch: 82/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.38it/s, loss:0.2669, acc:90.7500%]\n",
      "Val loss: 0.3866, accuracy: 87.78%\n",
      "Epoch: 83/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.56it/s, loss:0.2556, acc:91.1000%]\n",
      "Val loss: 0.4952, accuracy: 84.85%\n",
      "Epoch: 84/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.09it/s, loss:0.2621, acc:90.7900%]\n",
      "Val loss: 0.4884, accuracy: 85.69%\n",
      "Epoch: 85/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.29it/s, loss:0.2625, acc:90.8775%]\n",
      "Val loss: 0.4182, accuracy: 86.91%\n",
      "Epoch: 86/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.11it/s, loss:0.2651, acc:90.7575%]\n",
      "Val loss: 0.3871, accuracy: 87.57%\n",
      "Epoch: 87/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.61it/s, loss:0.2583, acc:91.1000%]\n",
      "Val loss: 0.4412, accuracy: 86.67%\n",
      "Epoch: 88/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.33it/s, loss:0.2543, acc:91.1075%]\n",
      "Val loss: 0.5181, accuracy: 84.61%\n",
      "Epoch: 89/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.33it/s, loss:0.2557, acc:91.0650%]\n",
      "Val loss: 0.4793, accuracy: 85.74%\n",
      "Epoch: 90/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.07it/s, loss:0.2568, acc:91.0700%]\n",
      "Val loss: 0.4095, accuracy: 86.68%\n",
      "Epoch: 91/180, lr:1.00e-01\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.57it/s, loss:0.2554, acc:91.0850%]\n",
      "Val loss: 0.3985, accuracy: 87.70%\n",
      "Epoch: 92/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.77it/s, loss:0.1468, acc:95.0450%]\n",
      "Val loss: 0.2449, accuracy: 92.27%\n",
      "Epoch: 93/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.88it/s, loss:0.1075, acc:96.3975%]\n",
      "Val loss: 0.2462, accuracy: 92.33%\n",
      "Epoch: 94/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.74it/s, loss:0.0953, acc:96.8450%]\n",
      "Val loss: 0.2494, accuracy: 92.37%\n",
      "Epoch: 95/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.93it/s, loss:0.0861, acc:97.0350%]\n",
      "Val loss: 0.2490, accuracy: 92.46%\n",
      "Epoch: 96/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.74it/s, loss:0.0794, acc:97.3550%]\n",
      "Val loss: 0.2501, accuracy: 92.64%\n",
      "Epoch: 97/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.67it/s, loss:0.0738, acc:97.4400%]\n",
      "Val loss: 0.2561, accuracy: 92.76%\n",
      "Epoch: 98/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.65it/s, loss:0.0665, acc:97.7400%]\n",
      "Val loss: 0.2584, accuracy: 92.73%\n",
      "Epoch: 99/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.58it/s, loss:0.0635, acc:97.8650%]\n",
      "Val loss: 0.2621, accuracy: 92.53%\n",
      "Epoch: 100/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.55it/s, loss:0.0609, acc:97.9325%]\n",
      "Val loss: 0.2650, accuracy: 92.67%\n",
      "Epoch: 101/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:24<00:00, 25.01it/s, loss:0.0578, acc:98.1075%]\n",
      "Val loss: 0.2720, accuracy: 92.59%\n",
      "Epoch: 102/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.93it/s, loss:0.0544, acc:98.2275%]\n",
      "Val loss: 0.2768, accuracy: 92.47%\n",
      "Epoch: 103/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.90it/s, loss:0.0504, acc:98.3725%]\n",
      "Val loss: 0.2772, accuracy: 92.74%\n",
      "Epoch: 104/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.83it/s, loss:0.0505, acc:98.2600%]\n",
      "Val loss: 0.2767, accuracy: 92.66%\n",
      "Epoch: 105/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.63it/s, loss:0.0467, acc:98.4075%]\n",
      "Val loss: 0.2781, accuracy: 92.74%\n",
      "Epoch: 106/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.98it/s, loss:0.0441, acc:98.5175%]\n",
      "Val loss: 0.2837, accuracy: 92.66%\n",
      "Epoch: 107/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.93it/s, loss:0.0422, acc:98.5875%]\n",
      "Val loss: 0.2871, accuracy: 92.72%\n",
      "Epoch: 108/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.99it/s, loss:0.0413, acc:98.7025%]\n",
      "Val loss: 0.2825, accuracy: 92.59%\n",
      "Epoch: 109/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.69it/s, loss:0.0393, acc:98.7175%]\n",
      "Val loss: 0.2855, accuracy: 92.60%\n",
      "Epoch: 110/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.74it/s, loss:0.0383, acc:98.7650%]\n",
      "Val loss: 0.2907, accuracy: 92.61%\n",
      "Epoch: 111/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.72it/s, loss:0.0357, acc:98.8725%]\n",
      "Val loss: 0.2907, accuracy: 92.61%\n",
      "Epoch: 112/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.66it/s, loss:0.0355, acc:98.7950%]\n",
      "Val loss: 0.2966, accuracy: 92.73%\n",
      "Epoch: 113/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.75it/s, loss:0.0336, acc:98.9725%]\n",
      "Val loss: 0.2976, accuracy: 92.65%\n",
      "Epoch: 114/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.87it/s, loss:0.0328, acc:98.9000%]\n",
      "Val loss: 0.2986, accuracy: 92.65%\n",
      "Epoch: 115/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.78it/s, loss:0.0325, acc:98.9275%]\n",
      "Val loss: 0.3041, accuracy: 92.73%\n",
      "Epoch: 116/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.64it/s, loss:0.0313, acc:98.9725%]\n",
      "Val loss: 0.3234, accuracy: 92.54%\n",
      "Epoch: 117/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.54it/s, loss:0.0306, acc:98.9925%]\n",
      "Val loss: 0.3116, accuracy: 92.81%\n",
      "Epoch: 118/180, lr:1.00e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:25<00:00, 24.45it/s, loss:0.0277, acc:99.0900%]\n",
      "Val loss: 0.3069, accuracy: 92.78%\n",
      "Epoch: 119/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.64it/s, loss:0.0290, acc:99.0375%]\n",
      "Val loss: 0.3141, accuracy: 92.48%\n",
      "Epoch: 120/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.72it/s, loss:0.0283, acc:99.1225%]\n",
      "Val loss: 0.3243, accuracy: 92.49%\n",
      "Epoch: 121/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.46it/s, loss:0.0280, acc:99.1250%]\n",
      "Val loss: 0.3182, accuracy: 92.55%\n",
      "Epoch: 122/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.68it/s, loss:0.0260, acc:99.1525%]\n",
      "Val loss: 0.3110, accuracy: 92.78%\n",
      "Epoch: 123/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.51it/s, loss:0.0256, acc:99.1675%]\n",
      "Val loss: 0.3248, accuracy: 92.69%\n",
      "Epoch: 124/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.51it/s, loss:0.0252, acc:99.1825%]\n",
      "Val loss: 0.3325, accuracy: 92.56%\n",
      "Epoch: 125/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.54it/s, loss:0.0263, acc:99.0850%]\n",
      "Val loss: 0.3259, accuracy: 92.51%\n",
      "Epoch: 126/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.46it/s, loss:0.0266, acc:99.1725%]\n",
      "Val loss: 0.3234, accuracy: 92.65%\n",
      "Epoch: 127/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.45it/s, loss:0.0241, acc:99.2150%]\n",
      "Val loss: 0.3235, accuracy: 92.82%\n",
      "Epoch: 128/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.95it/s, loss:0.0237, acc:99.2425%]\n",
      "Val loss: 0.3341, accuracy: 92.55%\n",
      "Epoch: 129/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.38it/s, loss:0.0242, acc:99.2350%]\n",
      "Val loss: 0.3256, accuracy: 92.62%\n",
      "Epoch: 130/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.51it/s, loss:0.0233, acc:99.2550%]\n",
      "Val loss: 0.3369, accuracy: 92.47%\n",
      "Epoch: 131/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.68it/s, loss:0.0253, acc:99.2450%]\n",
      "Val loss: 0.3321, accuracy: 92.69%\n",
      "Epoch: 132/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.46it/s, loss:0.0265, acc:99.1200%]\n",
      "Val loss: 0.3353, accuracy: 92.59%\n",
      "Epoch: 133/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.50it/s, loss:0.0234, acc:99.2350%]\n",
      "Val loss: 0.3359, accuracy: 92.61%\n",
      "Epoch: 134/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.25it/s, loss:0.0234, acc:99.2400%]\n",
      "Val loss: 0.3279, accuracy: 92.49%\n",
      "Epoch: 135/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.61it/s, loss:0.0243, acc:99.2125%]\n",
      "Val loss: 0.3401, accuracy: 92.43%\n",
      "Epoch: 136/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.50it/s, loss:0.0234, acc:99.2700%]\n",
      "Val loss: 0.3290, accuracy: 92.57%\n",
      "Epoch: 137/180, lr:1.00e-02\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.60it/s, loss:0.0209, acc:99.3375%]\n",
      "Val loss: 0.3429, accuracy: 92.57%\n",
      "Epoch: 138/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.50it/s, loss:0.0180, acc:99.4500%]\n",
      "Val loss: 0.3215, accuracy: 92.93%\n",
      "Epoch: 139/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.60it/s, loss:0.0143, acc:99.5875%]\n",
      "Val loss: 0.3153, accuracy: 93.11%\n",
      "Epoch: 140/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.72it/s, loss:0.0143, acc:99.5775%]\n",
      "Val loss: 0.3188, accuracy: 92.98%\n",
      "Epoch: 141/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.47it/s, loss:0.0134, acc:99.6225%]\n",
      "Val loss: 0.3156, accuracy: 93.01%\n",
      "Epoch: 142/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.60it/s, loss:0.0128, acc:99.6875%]\n",
      "Val loss: 0.3143, accuracy: 93.06%\n",
      "Epoch: 143/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.71it/s, loss:0.0123, acc:99.6450%]\n",
      "Val loss: 0.3108, accuracy: 93.11%\n",
      "Epoch: 144/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.39it/s, loss:0.0120, acc:99.6600%]\n",
      "Val loss: 0.3183, accuracy: 93.06%\n",
      "Epoch: 145/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.81it/s, loss:0.0116, acc:99.6650%]\n",
      "Val loss: 0.3155, accuracy: 93.11%\n",
      "Epoch: 146/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.50it/s, loss:0.0105, acc:99.7500%]\n",
      "Val loss: 0.3127, accuracy: 93.10%\n",
      "Epoch: 147/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.62it/s, loss:0.0114, acc:99.7275%]\n",
      "Val loss: 0.3170, accuracy: 93.11%\n",
      "Epoch: 148/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:26<00:00, 23.43it/s, loss:0.0108, acc:99.7500%]\n",
      "Val loss: 0.3136, accuracy: 93.21%\n",
      "Epoch: 149/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.29it/s, loss:0.0102, acc:99.7750%]\n",
      "Val loss: 0.3173, accuracy: 93.12%\n",
      "Epoch: 150/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.51it/s, loss:0.0097, acc:99.7700%]\n",
      "Val loss: 0.3163, accuracy: 93.14%\n",
      "Epoch: 151/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.85it/s, loss:0.0100, acc:99.7725%]\n",
      "Val loss: 0.3164, accuracy: 93.06%\n",
      "Epoch: 152/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.42it/s, loss:0.0100, acc:99.7350%]\n",
      "Val loss: 0.3168, accuracy: 93.14%\n",
      "Epoch: 153/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.86it/s, loss:0.0099, acc:99.7775%]\n",
      "Val loss: 0.3202, accuracy: 93.08%\n",
      "Epoch: 154/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.64it/s, loss:0.0104, acc:99.7275%]\n",
      "Val loss: 0.3151, accuracy: 93.14%\n",
      "Epoch: 155/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.45it/s, loss:0.0101, acc:99.7575%]\n",
      "Val loss: 0.3132, accuracy: 93.14%\n",
      "Epoch: 156/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.73it/s, loss:0.0095, acc:99.7925%]\n",
      "Val loss: 0.3150, accuracy: 93.17%\n",
      "Epoch: 157/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.73it/s, loss:0.0095, acc:99.7825%]\n",
      "Val loss: 0.3178, accuracy: 93.15%\n",
      "Epoch: 158/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.83it/s, loss:0.0086, acc:99.8150%]\n",
      "Val loss: 0.3178, accuracy: 93.09%\n",
      "Epoch: 159/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.75it/s, loss:0.0099, acc:99.7650%]\n",
      "Val loss: 0.3231, accuracy: 93.06%\n",
      "Epoch: 160/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.43it/s, loss:0.0087, acc:99.8075%]\n",
      "Val loss: 0.3179, accuracy: 93.16%\n",
      "Epoch: 161/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.91it/s, loss:0.0092, acc:99.7725%]\n",
      "Val loss: 0.3236, accuracy: 93.07%\n",
      "Epoch: 162/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.67it/s, loss:0.0088, acc:99.7950%]\n",
      "Val loss: 0.3202, accuracy: 93.14%\n",
      "Epoch: 163/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.59it/s, loss:0.0079, acc:99.8200%]\n",
      "Val loss: 0.3238, accuracy: 93.08%\n",
      "Epoch: 164/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.59it/s, loss:0.0096, acc:99.7675%]\n",
      "Val loss: 0.3210, accuracy: 93.16%\n",
      "Epoch: 165/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.23it/s, loss:0.0089, acc:99.7900%]\n",
      "Val loss: 0.3231, accuracy: 93.25%\n",
      "Epoch: 166/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.91it/s, loss:0.0084, acc:99.8000%]\n",
      "Val loss: 0.3254, accuracy: 93.12%\n",
      "Epoch: 167/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 25.00it/s, loss:0.0087, acc:99.7900%]\n",
      "Val loss: 0.3285, accuracy: 93.19%\n",
      "Epoch: 168/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.61it/s, loss:0.0083, acc:99.8150%]\n",
      "Val loss: 0.3232, accuracy: 93.21%\n",
      "Epoch: 169/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.34it/s, loss:0.0085, acc:99.7800%]\n",
      "Val loss: 0.3221, accuracy: 93.15%\n",
      "Epoch: 170/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.57it/s, loss:0.0082, acc:99.8300%]\n",
      "Val loss: 0.3218, accuracy: 93.18%\n",
      "Epoch: 171/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.47it/s, loss:0.0086, acc:99.7975%]\n",
      "Val loss: 0.3242, accuracy: 93.12%\n",
      "Epoch: 172/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.31it/s, loss:0.0076, acc:99.8475%]\n",
      "Val loss: 0.3244, accuracy: 93.13%\n",
      "Epoch: 173/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.75it/s, loss:0.0081, acc:99.8150%]\n",
      "Val loss: 0.3267, accuracy: 93.15%\n",
      "Epoch: 174/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.93it/s, loss:0.0076, acc:99.8375%]\n",
      "Val loss: 0.3250, accuracy: 93.12%\n",
      "Epoch: 175/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.76it/s, loss:0.0076, acc:99.8550%]\n",
      "Val loss: 0.3268, accuracy: 93.12%\n",
      "Epoch: 176/180, lr:1.00e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:25<00:00, 24.73it/s, loss:0.0077, acc:99.8375%]\n",
      "Val loss: 0.3276, accuracy: 93.04%\n",
      "Epoch: 177/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.87it/s, loss:0.0082, acc:99.8025%]\n",
      "Val loss: 0.3280, accuracy: 93.05%\n",
      "Epoch: 178/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.67it/s, loss:0.0083, acc:99.8050%]\n",
      "Val loss: 0.3277, accuracy: 93.07%\n",
      "Epoch: 179/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.98it/s, loss:0.0080, acc:99.8025%]\n",
      "Val loss: 0.3279, accuracy: 93.01%\n",
      "Epoch: 180/180, lr:1.00e-03\n",
      "100%|██████████| 625/625 [00:25<00:00, 24.79it/s, loss:0.0079, acc:99.8250%]\n",
      "Val loss: 0.3245, accuracy: 93.09%\n",
      "Test loss: 0.3512, accuracy: 92.53%\n",
      "CPU times: user 1h 13min 34s, sys: 9min 32s, total: 1h 23min 7s\n",
      "Wall time: 1h 22min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "opt = optim.SGD(model.parameters(), lr=1e-1, momentum=0.9, weight_decay=1e-4, nesterov=False)\n",
    "loss_fn = F.cross_entropy\n",
    "\n",
    "lr_scheduler= optim.lr_scheduler.MultiStepLR(opt, milestones=[91, 137], gamma=0.1)\n",
    "history = main(model, opt, epoch=180, loss_fn=loss_fn, lr_scheduler=lr_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot loss history\n",
    "We check the classifier by plotting the loss and acc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a8489d1127d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
